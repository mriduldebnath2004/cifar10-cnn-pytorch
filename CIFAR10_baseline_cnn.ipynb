{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e47869-c88f-4986-9613-edd9596efddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "#torch for tensor manipulation, and gpu functionality\n",
    "#torch.nn for neural network building\n",
    "#optim has optimization algorithms like Adam\n",
    "#torch.utils.data dataloader for batching and shuffling dataset, subset to create set for training\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "#torchvision for loading and preprocessing dataset\n",
    "#torchvision transforms to preprocess and convert images for neural networks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "#matplotlib to visualize data and training results\n",
    "#numpy for basic matrix manipulation\n",
    "#time to measure training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b64032d-5c09-4cad-b7d2-7fe7fe20c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "#scales pixels and converts images to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d51d76e-f5cd-43b4-9836-9bf0c2a89ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#Load CIFAR-10 dataset and apply transform to each image\n",
    "\n",
    "classes = [ \"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\" ]\n",
    "#labels of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71250123-d0d0-46f8-a898-e24f902b99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "#creates iterable with shuffled batches of 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "227555ec-bc96-4632-80c1-2e5321db21c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4914, 0.4822, 0.4465]) tensor([0.2470, 0.2435, 0.2616]) 51200000\n"
     ]
    }
   ],
   "source": [
    "#find the mean and std of training dataset to normalize it after\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "total_pixels = 0\n",
    "\n",
    "for images, _ in train_dataloader:\n",
    "    b,c,h,w = images.shape\n",
    "    pixels = b*h*w\n",
    "    total_pixels += pixels\n",
    "#find total pixels by getting the dimensions of data\n",
    "    \n",
    "    mean += images.sum(dim=[0, 2, 3])\n",
    "    std += (images**2).sum(dim=[0, 2, 3])\n",
    "#find the sum of pixel value across all color chanels (R,G,B) and sum^2 (to find mean and std deviation after) \n",
    "\n",
    "mean /= total_pixels\n",
    "std = torch.sqrt(std / total_pixels - mean ** 2)\n",
    "#calculate mean and std deviation of each color channel in dataset\n",
    "print(mean, std, total_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d021136-d6e8-4619-9242-7b330b23fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),               \n",
    "    transforms.Normalize(mean, std)  #updated transform fcn which normalizes too now\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "#Load dataset again and apply transform including normalization to each image\n",
    "\n",
    "total_indices = torch.randperm(len(train_set)).tolist()\n",
    "train_subset = Subset(train_dataset, total_indices[:40000])\n",
    "validation_subset = Subset(train_dataset, total_indices[40000:])\n",
    "\n",
    "#training data set - 40000 images with random indices for \n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(validation_subset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6610b111-7161-485d-91fc-550b25e99f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,32,3,padding = 1) #input 3(RGB channels), output channels of 32(32 features), 3x3 kernel, padding to keep edge data\n",
    "        self.pool = nn.MaxPool2d(2,2) #2x2 kernel, stride of 2 to halve the matrix after first pool\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding = 1) #input is 32 this time, have 64 features as output for complex features\n",
    "        self.fc1 = nn.Linear(64*8*8, 128) #input of 64 channels by 8x8 (32x32 with padding=1 after two pools), and 128 neurons in this layer\n",
    "        self.fc2 = nn.Linear(128, 10) #input of the 128 neurons to output logits for each 10 classes\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x))) #conv - activation - pool first layer ouputs\n",
    "        x = self.pool(torch.relu(self.conv2(x))) #pool second layer outputs\n",
    "        x = torch.flatten(x, 1) #fc1 expects a 2d input\n",
    "        x = torch.relu(self.fc1(x)) #activation fcn on each output\n",
    "        x = self.fc2(x) #final output of batch size x 10 for each class\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a80308a-a924-4101-82b8-8e8a9920cb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN() #instantiate our model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Nvidia GPU\n",
    "model = model.to(device) #use the gpu for parallel processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8efa736-639d-4036-932d-d1ae897868fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() #basic loss generally used for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) #basic adaptive moment optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00147e22-08e2-4c1b-b76b-456441ad6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20 #training loops going through entire train set\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device) #send inputs to GPU\n",
    "\n",
    "        #forward step to find output guesses\n",
    "        outputs = model(images) #goes through CNN process to find final logits\n",
    "        loss = criterion(outputs, labels) #calculates the loss\n",
    "\n",
    "        #backprop to optimize weights\n",
    "        optimizer.zero_grad() #resets gradient every batch, else would keep adding\n",
    "        loss.backward() #backward prop to find dL/dw\n",
    "        optimizer.step() #changes weights accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d18041f-877a-47d7-bac6-920c59a517b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.14%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  #sets model to eval mode and turns off training features \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  #turn off gradient tracking, only evaluating right now\n",
    "    for images, labels in val_loader:  #using validation dataset\n",
    "        images, labels = images.to(device), labels.to(device) #use gpu\n",
    "        outputs = model(images) #forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  #get only the class with highest score\n",
    "        total += labels.size(0) #find total # of images\n",
    "        correct += (predicted == labels).sum().item() #find # of correct guesses\n",
    "\n",
    "print(\"Test Accuracy: {:.2f}%\".format(100 * correct / total)) #only looking at accuracy, recall not required as dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fef9d-85c0-4ea9-8cfe-bcc2b07c8091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
